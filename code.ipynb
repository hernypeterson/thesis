{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import radians as rad\n",
    "from numpy import degrees as deg\n",
    "from numpy import sin, cos, tan, arcsin, arccos, arctan, arctan2, mean\n",
    "\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "import itertools\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from typing import Callable, Tuple\n",
    "from collections.abc import Iterable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHEAR_MODULUS = 2.4e10  # Pa\n",
    "ROCK_DENSITY = 2700  # kg / m^3\n",
    "MAGMA_DENSITY = 2700  # kg / m^3\n",
    "MARS_GRAVITY = 3.72  # m / s^2\n",
    "MARS_EQ_RADIUS = 3_396_200  # m\n",
    "\n",
    "AZ1_UNCERTAINTY = 7  # degrees\n",
    "\n",
    "# for plotting numerical\n",
    "PLOT_WIDTH = 200_000\n",
    "\n",
    "# scale length dimensions to prevent overflow\n",
    "LENGTH_SCALE_MULT = 1_000_000\n",
    "\n",
    "# for cutoff envelope and first guess in non-linear regression\n",
    "MAX_EPV = 7e22  # J\n",
    "TEST_D = 20_000  # m\n",
    "MAX_ITERATIONS = 80\n",
    "\n",
    "# parameter conversion factor\n",
    "EPV_OVER_K = 16 * np.pi * SHEAR_MODULUS / 9"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pdf(name: str = 'plot'):\n",
    "    plt.tight_layout()  # prevent clipping edge labels\n",
    "    plt.savefig(f'figures/{name}.pdf')\n",
    "\n",
    "\n",
    "def mogi_tilt(dist, epv, d):\n",
    "    k = epv / EPV_OVER_K\n",
    "\n",
    "    # scale to prevent overflow\n",
    "    r1_scale = dist / LENGTH_SCALE_MULT\n",
    "    k_scale = k / (LENGTH_SCALE_MULT ** 3)\n",
    "    d_scale = d / LENGTH_SCALE_MULT\n",
    "\n",
    "    num = 3 * k_scale * d_scale * r1_scale\n",
    "    denom = (d_scale**2 + r1_scale**2)**2.5 + \\\n",
    "        k_scale * (d_scale**2 - 2*r1_scale**2)\n",
    "    return np.degrees(np.arctan2(num, denom))\n",
    "\n",
    "\n",
    "def calculate_epv(depth, radius, aspect, pmult):\n",
    "    half_height = radius * aspect\n",
    "    volume = (4/3) * np.pi * radius**2 * half_height\n",
    "    pressure = ROCK_DENSITY * MARS_GRAVITY * depth * pmult\n",
    "    return volume * pressure\n",
    "\n",
    "\n",
    "def dist(lat_sample, lon_sample, lat_center, lon_center):\n",
    "    '''distance between pts 1 and 2'''\n",
    "    lat1 = rad(lat_sample)\n",
    "    lon1 = rad(lon_sample)\n",
    "    lat2 = rad(lat_center)\n",
    "    lon2 = rad(lon_center)\n",
    "    rads = arccos(\n",
    "        cos(lat1) * cos(lat2)\n",
    "        * cos(lon2 - lon1)\n",
    "        + sin(lat1) * sin(lat2)\n",
    "    )\n",
    "    return rads * MARS_EQ_RADIUS\n",
    "\n",
    "\n",
    "def bearing(lat_sample, lon_sample, lat_center, lon_center):\n",
    "    '''angle from pt 1 AWAY from pt 2'''\n",
    "    lat1 = rad(lat_sample)\n",
    "    lon1 = rad(lon_sample)\n",
    "    lat2 = rad(lat_center)\n",
    "    lon2 = rad(lon_center)\n",
    "    y = sin(lon2 - lon1) * cos(lat2)\n",
    "    x = cos(lat1) * sin(lat2) \\\n",
    "        - sin(lat1) * cos(lat2) * cos(lon2 - lon1)\n",
    "    return (180 + deg(arctan2(y, x))) % 360\n",
    "\n",
    "\n",
    "# for beta, discordance calculations\n",
    "def signed_ang_diff(az, bearing):\n",
    "    return ((az - bearing + 180) % 360) - 180\n",
    "\n",
    "\n",
    "def sl1(beta1, beta2, sl2):\n",
    "    beta1 = rad(beta1)\n",
    "    beta2 = rad(beta2)\n",
    "    sl2 = rad(sl2)\n",
    "    arg = sin(beta2) * sin(sl2) / sin(beta1)\n",
    "    if arg < 0 or arg > 1:  # not possible\n",
    "        return np.nan\n",
    "    else:\n",
    "        sl1 = arcsin(arg)\n",
    "        return deg(sl1)\n",
    "\n",
    "\n",
    "def proj(beta, sl):\n",
    "    '''project small circle point onto great circle'''\n",
    "    beta = rad(beta)\n",
    "    sl = rad(sl)\n",
    "    proj = arctan(tan(beta) * cos(beta))\n",
    "    return deg(proj)\n",
    "\n",
    "\n",
    "def tilt(beta1_measured, beta2, sl2, dist, az1_uncertainty=AZ1_UNCERTAINTY):\n",
    "\n",
    "    # within uncertainty (non-discordance condition)\n",
    "    if np.abs(signed_ang_diff(beta1_measured, beta2)) < az1_uncertainty:\n",
    "        return 0 # early exit from function\n",
    "\n",
    "    # beta1 uncertainty boundaries \n",
    "    beta1_possible = np.array([\n",
    "        beta1_measured + az1_uncertainty,\n",
    "        beta1_measured - az1_uncertainty\n",
    "    ])\n",
    "\n",
    "    # compute resulting sl1 for each beta1 boundary\n",
    "    sl1_possible = np.array([\n",
    "        sl1(beta1, beta2, sl2) for beta1 in beta1_possible\n",
    "    ])\n",
    "\n",
    "    # remove any impossible boundary calculations\n",
    "    beta1_possible = beta1_possible[~np.isnan(sl1_possible)]\n",
    "    sl1_possible = sl1_possible[~np.isnan(sl1_possible)]\n",
    "\n",
    "    # make (beta1, sl1) pairs of resulting (mathematically possible)\n",
    "    beta1_sl1_zip = zip(beta1_possible, sl1_possible)\n",
    "\n",
    "    # no possible tilts (mathematical condition)\n",
    "    if len(sl1_possible) == 0:\n",
    "        return np.nan # early exit from function\n",
    "\n",
    "    # evaluate tilt for \n",
    "    tilt_possible = np.array(\n",
    "        [proj(beta2, sl2) - proj(*pair)for pair in beta1_sl1_zip]\n",
    "    )\n",
    "\n",
    "    # find index (boundary) with the lowest tilt magnitude \n",
    "    lowest_abs_tilt_arg = np.argmin(np.abs(tilt_possible))\n",
    "\n",
    "    # envelope cutoff (physical plausibility condition)\n",
    "    max_tilt = mogi_tilt(dist=dist, epv=MAX_EPV, d=TEST_D)\n",
    "    min_tilt = mogi_tilt(dist=dist, epv=-MAX_EPV, d=TEST_D)\n",
    "\n",
    "    if tilt_possible[lowest_abs_tilt_arg] > max_tilt:\n",
    "        return np.nan # early exit\n",
    "    if tilt_possible[lowest_abs_tilt_arg] < min_tilt:\n",
    "        return np.nan # early exit\n",
    "\n",
    "    # if no early exits, return lowest computed tilt \n",
    "    return tilt_possible[lowest_abs_tilt_arg]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Envelope plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8, 3), dpi=600)\n",
    "\n",
    "test_dist = np.arange(1, 100_000)\n",
    "test_max_tilt = mogi_tilt(test_dist, MAX_EPV, TEST_D)\n",
    "test_min_tilt = mogi_tilt(test_dist, -MAX_EPV, TEST_D)\n",
    "test_dist_km = test_dist / 1000\n",
    "\n",
    "sns.lineplot(x=test_dist_km,y=test_max_tilt,label='Maximum')\n",
    "sns.lineplot(x=test_dist_km,y=test_min_tilt,label='Minimum')\n",
    "plt.title(f'Tilt Cutoff Envelope using $d = ${TEST_D/1000} km, ' + \"$E_{PV} = $\" + f'{MAX_EPV} J')\n",
    "plt.xlabel('Tilt (deg)')\n",
    "plt.xlabel('Distance (km)')\n",
    "\n",
    "def add_envelope_to_plot(min: bool = True, max: bool = True):\n",
    "    if max:\n",
    "        sns.lineplot(x=test_dist_km,y=test_max_tilt, c='black', linestyle='--')\n",
    "    if min:\n",
    "        sns.lineplot(x=test_dist_km,y=test_min_tilt, c='black', linestyle='--')\n",
    "\n",
    "# save_pdf(name='envelope')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Data\n",
    "\n",
    "Read samples.csv and centers.csv and extract IDs for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location to read .csv files\n",
    "map_path = \"../GEOL192-GIS/data/\"\n",
    "\n",
    "\n",
    "centers = pd.read_csv(f'{map_path}centers.csv').set_index('cID')\n",
    "samples = pd.read_csv(f'{map_path}samples.csv').set_index(['sID', 'FEATURE'])\n",
    "\n",
    "cIDs = tuple(centers.index)\n",
    "sIDs = tuple(index[0] for index in samples.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an object to organize, calculate, and plot map data for a single center point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Center:\n",
    "    cID: int\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.data = samples.copy()\n",
    "\n",
    "        # this of course only works for unique self.cIDs\n",
    "        self.lat = centers.loc[self.cID, 'LAT']\n",
    "        self.lon = centers.loc[self.cID, 'LON']\n",
    "        self.calculate()\n",
    "\n",
    "    def plot(self, name: str = None):  # type: ignore\n",
    "        fig = plt.figure(figsize=(8, 5), dpi=600)\n",
    "\n",
    "        sns.scatterplot(data=self.data, x='dist', y='tilt')\n",
    "\n",
    "        plt.title(f\"Tilt from Center {self.cID} under cutoff: {MAX_EPV = }, {TEST_D = }\")\n",
    "        plt.xlabel(\"Distance (km)\")\n",
    "        plt.ylabel(\"Tilt (deg)\")\n",
    "\n",
    "        # save plot with name if passed as argument\n",
    "        if name is not None:\n",
    "            save_pdf(name)\n",
    "\n",
    "    def calculate(self):\n",
    "\n",
    "        self.data['dist'] = self.data.apply(\n",
    "            lambda row: dist(\n",
    "                lat_sample=row['LAT'], lon_sample=row['LON'],\n",
    "                lat_center=self.lat, lon_center=self.lon\n",
    "            ),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        self.data['dist_km'] = self.data.apply(\n",
    "            lambda row: row['dist'] / 1000,\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        self.data['bearing'] = self.data.apply(\n",
    "            lambda row: bearing(\n",
    "                lat_sample=row['LAT'], lon_sample=row['LON'],\n",
    "                lat_center=self.lat, lon_center=self.lon\n",
    "            ),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        self.data['beta1'] = self.data.apply(\n",
    "            lambda row: signed_ang_diff(\n",
    "                az=row['AZ1'], bearing=row['bearing']\n",
    "            ),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        self.data['beta2'] = self.data.apply(\n",
    "            lambda row: signed_ang_diff(\n",
    "                az=row['AZ2'], bearing=row['bearing']\n",
    "            ),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        self.data['tilt'] = self.data.apply(\n",
    "            lambda row: tilt(\n",
    "                beta1_measured=row['beta1'],\n",
    "                beta2=row['beta2'], sl2=row['SL2'],\n",
    "                dist=row['dist']\n",
    "            ),\n",
    "            axis=1\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an object for each center. This takes less than a minute on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_calc = [Center(cID) for cID in cIDs]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define sample populations based on their sIDs and feature type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Population:\n",
    "    feature: tuple = ('flow', 'channel')\n",
    "    name: str = ''\n",
    "    sIDs: tuple = sIDs  # type: ignore\n",
    "\n",
    "# not used\n",
    "SE_ALL_sIDs = (\n",
    "    41, 193, 194, 195, 196, 197, 198, 202, 203, 430, 431, 432, 438, 439, 440, 441, 442, 443, 444, 445, 477, 478, 479, 480, 481, 490,\n",
    "    491, 492, 493, 524, 525, 526, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549\n",
    ")\n",
    "\n",
    "POP_A_sIDs = (\n",
    "    198, 438, 439, 440, 441, 442, 443, 444, 445, 490, 491, 492, 493\n",
    ")\n",
    "\n",
    "POP_B_sIDs = (\n",
    "    193, 194, 195, 196, 197, 477, 478, 479, 480, 481, 544, 545, 548, 549\n",
    ")\n",
    "\n",
    "POP_C_sIDs = (\n",
    "    529, 530, 531, 532, 533, 537, 538, 539, 540, 541, 542, 543\n",
    ")\n",
    "\n",
    "pop_all = Population(name='all')\n",
    "pop_flow = Population(('flow',),name='flow')\n",
    "pop_channel = Population(('channel',),name='channel')\n",
    "\n",
    "pop_a = Population(name='A', sIDs=POP_A_sIDs)\n",
    "pop_b = Population(name='B', sIDs=POP_B_sIDs)\n",
    "pop_c = Population(name='C', sIDs=POP_C_sIDs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions for center evaluation. These return dicts with score names as keys. They need to return dicts of the same length with NaN values if any error occurs, rather than skipping or any other behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summit_score(df: pd.DataFrame) -> dict:\n",
    "    try:\n",
    "        score = {'summit_score': mean(np.abs(df['beta1']))}\n",
    "    except:\n",
    "        score = {'summit_score': np.nan}\n",
    "    return score\n",
    "\n",
    "\n",
    "def fit_mogi_function(df: pd.DataFrame):\n",
    "\n",
    "    # initial guess lower than envelope\n",
    "    if np.mean(df['tilt']) < 0:\n",
    "        p0 = -MAX_EPV / 1000, TEST_D\n",
    "    else:\n",
    "        p0 = MAX_EPV / 1000, TEST_D\n",
    "\n",
    "    params, pcov = curve_fit(\n",
    "        f=mogi_tilt,\n",
    "        xdata=df['dist'],\n",
    "        ydata=df['tilt'],\n",
    "        p0=p0,\n",
    "        maxfev=MAX_ITERATIONS,\n",
    "        method='lm'\n",
    "    )\n",
    "    return params, pcov\n",
    "\n",
    "\n",
    "def inflation_score(df: pd.DataFrame) -> dict:\n",
    "\n",
    "    # get size of population before taking tiltable subset\n",
    "    pop_size = len(df)\n",
    "    df = df.loc[df['tilt'].notnull()]\n",
    "\n",
    "    # initialize output\n",
    "    scores = {\n",
    "        'frac_tiltable': len(df) / pop_size,  # doesn't depend on fit results\n",
    "        'Epv_est': np.nan,\n",
    "        'log10_Epv_est': np.nan,\n",
    "        'Epv_is_positive': np.nan,\n",
    "        'Epv_err': np.nan,\n",
    "        'd_est': np.nan,\n",
    "        'd_err': np.nan,\n",
    "    }\n",
    "\n",
    "    # attempt regression\n",
    "    try:\n",
    "        params, pcov = fit_mogi_function(df)\n",
    "\n",
    "        # unpack param estimate and variance\n",
    "        epv, d = params\n",
    "        epv_var, d_var = np.sqrt(np.diag(pcov))\n",
    "\n",
    "        # calculate scores\n",
    "        scores['Epv_est'] = epv\n",
    "        scores['log10_Epv_est'] = np.log10(np.abs(epv))\n",
    "        scores['Epv_is_positive'] = epv > 0\n",
    "        scores['Epv_err'] = abs(epv_var / epv)\n",
    "        scores['d_est'] = d\n",
    "        scores['d_err'] = abs(d_var / d)\n",
    "\n",
    "    # if regression fails, keep null values for scores\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A criterion is just a combination of an evaluation function and a population on which to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Criterion:\n",
    "    func: Callable\n",
    "    pop: Population\n",
    "\n",
    "criteria = [\n",
    "    Criterion(summit_score, pop_all),\n",
    "    Criterion(summit_score, pop_flow),\n",
    "    Criterion(summit_score, pop_channel),\n",
    "    Criterion(inflation_score, pop_a),\n",
    "    Criterion(inflation_score, pop_b),\n",
    "    Criterion(inflation_score, pop_c),\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform each evaluation for each center point. This takes less than two minutes on my machine, the vast majority of which is from the curve_fit function calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_center(center: Center, crit: Criterion):\n",
    "    pop_subset = center.data.loc[(crit.pop.sIDs, crit.pop.feature), :]\n",
    "    return crit.func(pop_subset)\n",
    "\n",
    "\n",
    "scores = {}\n",
    "score_names = []\n",
    "\n",
    "# note: will get score name out of order if any criteria throw errors, so those need to be handled in each evaluation function\n",
    "for center in centers_calc:\n",
    "    centers_eval = []\n",
    "    for crit in criteria:\n",
    "        center_crit_scores = evaluate_center(center, crit)\n",
    "        for key, val in center_crit_scores.items():\n",
    "            centers_eval.append(val)\n",
    "\n",
    "            full_score_name = f'{crit.pop.name}_{key}'\n",
    "            if full_score_name not in score_names:\n",
    "                score_names.append(full_score_name)\n",
    "    scores[center.cID] = centers_eval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the evaluated scores to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_eval = pd.DataFrame(scores).transpose().set_axis(score_names, axis=1)\n",
    "\n",
    "# replace inf with NaN to ensure export as numbers\n",
    "centers_eval = centers_eval.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "centers_eval.to_csv(f'{map_path}centers_eval.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are computed parameters simply \"hugging\" those used to define the mogi tilt envelope? While they are centered around zero, they spread over multiple orders of magnitude, particularly the energy term which is much less constrained. Depth ranging over even a fraction of an oder of magnitude is convincing here (considering that the true range of realistic reservoir depths is a very narrow range)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def envelope_hugging(pops: list, name: str = None):  # type: ignore\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 4), dpi=600)\n",
    "    ax_epv = fig.add_subplot(1, 2, 1)\n",
    "    ax_d = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "    ax_d.yaxis.set_label_position(\"right\")\n",
    "    ax_d.yaxis.tick_right()\n",
    "\n",
    "    fig.suptitle(\n",
    "        f'Parameter Estimates \"Hugging\" Envelope with '\n",
    "        + \"$E_{PV} = $\" + f'{MAX_EPV} J, '\n",
    "        + f'$d = ${TEST_D/1000} km'\n",
    "    )\n",
    "\n",
    "    for pop in pops:\n",
    "\n",
    "        d_est = centers_eval[f'{pop.name}_d_est'][\n",
    "            centers_eval[f'{pop.name}_d_est'].notna()\n",
    "        ]\n",
    "        epv_est = centers_eval[f'{pop.name}_Epv_est'][\n",
    "            centers_eval[f'{pop.name}_Epv_est'].notna()\n",
    "        ]\n",
    "\n",
    "        n_d = len(d_est)\n",
    "        n_epv = len(epv_est)\n",
    "\n",
    "        sns.kdeplot(x=np.log10(np.abs(epv_est / MAX_EPV)),\n",
    "                    ax=ax_epv, label=f'{pop.name} (n = {n_epv})')\n",
    "\n",
    "        sns.kdeplot(x=d_est / TEST_D, ax=ax_d, label=f'{pop.name} (n = {n_d})',bw_adjust=3)\n",
    "\n",
    "    plt.sca(ax_d)\n",
    "    plt.ylim((None, None))\n",
    "    ax_d.vlines(x=1, ymin=0, ymax=1, colors=['black'])\n",
    "    plt.xlabel('$d:$ fit / envelope')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.sca(ax_epv)\n",
    "    plt.ylim((None, None))\n",
    "    ax_epv.vlines(x=0, ymin=0, ymax=1, colors=['black'])\n",
    "    plt.xlabel('$E_{PV}:$ log |fit / envelope|')\n",
    "    plt.legend()\n",
    "\n",
    "    if name is not None:\n",
    "        save_pdf(name)\n",
    "\n",
    "envelope_hugging([pop_a], ) # name='hugging-a'\n",
    "envelope_hugging([pop_c], ) # name='hugging-c'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine scatter plots and mogi fit functions for individual center candidates relative to a population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_fit(cIDs: list, pop: Population, name: str = None, show_max: bool = False, show_min: bool = False, height: int = 3):  # type: ignore\n",
    "\n",
    "    fig = plt.figure(figsize=(8, height), dpi=600)\n",
    "\n",
    "    for cID in cIDs:\n",
    "        spot_check = centers_calc[cID - 1].data.loc[(pop.sIDs, pop.feature), :]\n",
    "        sns.scatterplot(data=spot_check, x='dist_km', y='tilt')\n",
    "        eval = centers_eval.loc[cID]\n",
    "\n",
    "        pv = eval[f'{pop.name}_Epv_est']\n",
    "        d = eval[f'{pop.name}_d_est']\n",
    "\n",
    "        frac = round(eval[f'{pop.name}_frac_tiltable'],1)\n",
    "\n",
    "        if not np.isnan(pv):\n",
    "            mogi_dist = np.linspace(\n",
    "                0,\n",
    "                np.max(spot_check['dist'][spot_check['tilt'].notna()]),\n",
    "                100\n",
    "            )\n",
    "            mogi_dist_km = mogi_dist / 1000\n",
    "            label = f\"cID: {cID}. \" + \"$\\\\log|E_{pv}\\\\ /\\\\ J|$: \" + \\\n",
    "                f\"{round(np.log10(np.abs(pv)),1)}, $d$: {round(d)} (f = {frac})\"\n",
    "            sns.lineplot(x=mogi_dist_km, y=mogi_tilt(\n",
    "                mogi_dist, pv, d), label=label)\n",
    "\n",
    "    # set extent based on data first, then add envelope\n",
    "    plt.xlim(0, None)\n",
    "    plt.ylim(None, None)\n",
    "    add_envelope_to_plot(max=show_max, min=show_min)\n",
    "\n",
    "    plt.ylabel('Tilt (deg)')\n",
    "    plt.xlabel('Distance (km)')\n",
    "    plt.title(f'Center Candidates for Pop. {pop.name}')\n",
    "    plt.legend(loc='upper left') #\n",
    "\n",
    "    # save plot with name if passed as argument\n",
    "    if name is not None:\n",
    "        save_pdf(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter_fit(\n",
    "    [41, 81, 102, 103], pop_a, show_min=True, show_max=True, height=5,\n",
    ") # name='scatter-fit-a'\n",
    "\n",
    "plot_scatter_fit(\n",
    "    [197], pop_a, show_min=True, show_max=True,\n",
    ") # name='scatter-fit-a-outlier'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Model Data\n",
    "\n",
    "Read initial positions and displacement vectors (radial and vertical components) of mesh nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../GEOL192-Model/data/\"\n",
    "\n",
    "# paleo-edifice spline data\n",
    "topo = np.genfromtxt(f'{model_path}z1.csv', delimiter=\",\")\n",
    "\n",
    "\n",
    "def model_pos1_from_csv(name: str):\n",
    "    r = np.genfromtxt(model_path + \"rdisp_\" + name, delimiter=\",\")[:, 0]\n",
    "    z = np.interp(r, *topo.T, right=0) # interpolate z1 into topography\n",
    "    return np.array([r, z]).T\n",
    "\n",
    "\n",
    "def model_disp_from_csv(name: str):\n",
    "    r = np.genfromtxt(f'{model_path}rdisp_{name}', delimiter=\",\")[:, 1]\n",
    "    z = np.genfromtxt(f'{model_path}zdisp_{name}', delimiter=\",\")[:, 1]\n",
    "    return np.array([r, z]).T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define objects for displaced nodes and surface edges (the latter defined by a consecutive pair of the former). Tilt calculation in the edge class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Node:\n",
    "    pos1: Tuple[float, float]\n",
    "    disp: Tuple[float, float]\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.pos2 = self.pos1 + self.disp\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Edge:\n",
    "    proximal: Node  # (A in text)\n",
    "    distal: Node  # (B in text)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # relative dimensions [r, z] of initial and displaced segments\n",
    "        self.shape1 = self.distal.pos1 - self.proximal.pos1  # type: ignore\n",
    "        self.shape2 = self.distal.pos2 - self.proximal.pos2  # type: ignore\n",
    "\n",
    "        # mean position of initial and displaced segments\n",
    "        self.pos1 = (self.distal.pos1 + self.proximal.pos1) / 2  # type: ignore\n",
    "        self.pos2 = (self.distal.pos2 + self.proximal.pos2) / 2  # type: ignore\n",
    "\n",
    "        # radial distances for plotting\n",
    "        self.dist = self.pos2[0]\n",
    "        self.dist_km = self.dist / 1000\n",
    "\n",
    "        # initial and displaced slopes (positive downward from center)\n",
    "        # index [1] is z component; [0] is r component\n",
    "        self.slope1 = deg(arctan2(-self.shape1[1], self.shape1[0]))\n",
    "        self.slope2 = deg(arctan2(-self.shape2[1], self.shape2[0]))\n",
    "\n",
    "        self.tilt = self.slope2 - self.slope1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model class with parameter combination (geometry, overpressure). It reads .csv files, builds nodes & edges, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Model:\n",
    "    params: dict\n",
    "\n",
    "    def __post_init__(self):\n",
    "\n",
    "        self.radius = self.params['radius']\n",
    "        self.half_height = self.radius * self.params['aspect']\n",
    "\n",
    "        self.dP = self.params['pmult'] * \\\n",
    "            self.params['depth'] * ROCK_DENSITY * MARS_GRAVITY\n",
    "\n",
    "        self.res_vol = (4 / 3) * np.pi * self.radius**2 * self.half_height\n",
    "\n",
    "        self.epv = self.dP * self.res_vol\n",
    "        self.d = self.params['depth'] + self.half_height\n",
    "\n",
    "        filename = f\"depth_{self.params['depth']}_radius_{self.params['radius']}_aspect_{self.params['aspect']}_pmult_{self.params['pmult']}_grav_{int(self.params['grav'])}_topo_{int(self.params['topo'])}.csv\"\n",
    "\n",
    "        # read initial positions and displacements\n",
    "        self.pos1 = model_pos1_from_csv(filename)\n",
    "        self.disp = model_disp_from_csv(filename)\n",
    "\n",
    "        # subtract out gravitational component (with no overpressure)\n",
    "        if self.params['grav']:\n",
    "            filename_p0 = filename.replace(\n",
    "                f\"pmult_{self.params['pmult']}\", \"pmult_0\")\n",
    "            self.disp -= model_disp_from_csv(filename_p0)\n",
    "\n",
    "        # make z1 flat for flat model\n",
    "        if not self.params['topo']:\n",
    "            self.pos1[1] = np.zeros(len(self.pos1[1]))\n",
    "\n",
    "        # build nodes from pos1 and disp if pos1 within defined length\n",
    "        self.num_nodes = next(i for i, val in enumerate(self.pos1)\n",
    "                              if val[0] > PLOT_WIDTH)\n",
    "\n",
    "        self.nodes = [Node(self.pos1[i], self.disp[i])\n",
    "                      for i in range(self.num_nodes)]\n",
    "\n",
    "        # build edges from consecutive node pairs\n",
    "        self.node_pairs = zip(self.nodes[:-1], self.nodes[1:])\n",
    "        self.edges = [Edge(*pair) for pair in self.node_pairs]\n",
    "\n",
    "        # put edge attributes into dict of lists\n",
    "        self.data = pd.DataFrame(\n",
    "            [vars(edge) for edge in self.edges])\n",
    "\n",
    "        self.attributes = self.data.to_dict(\"list\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define parametric sweep class to mirror COMSOL iterative modelling. It includes a flexible plot function which distinguishes between constant and variable parameters within the sweep and can handle comparisons with the analytical Mogi solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter sweep in SI units (to match csv output from COMSOL)\n",
    "class ParamSweep:\n",
    "    def __init__(self, params: dict):\n",
    "\n",
    "        # define constant parameters for labelling once in title\n",
    "        self.constants = {key: val[0]\n",
    "                          for key, val in params.items() if len(val) == 1}\n",
    "\n",
    "        # define variable parameters for labelling individually\n",
    "        self.variables = [key for key, val in params.items() if len(val) > 1]\n",
    "\n",
    "        self.models = [Model(dict(zip(params, item)))\n",
    "                       for item in itertools.product(*params.values())]\n",
    "\n",
    "    def plot(self, calc_mogi: bool = False, fit_mogi: bool = False, name: str = None):  # type: ignore\n",
    "\n",
    "        fig = plt.figure(figsize=(8, 3), dpi=600)\n",
    "\n",
    "        title = f'{self.constants}'.replace(\n",
    "            \"{\", \"\").replace(\"}\", \"\").replace(\"'\", \"\")\n",
    "        \n",
    "        for model in self.models:\n",
    "\n",
    "            model_epv = calculate_epv(\n",
    "                model.params['depth'],\n",
    "                model.params['radius'],\n",
    "                model.params['aspect'],\n",
    "                model.params['pmult']\n",
    "            )\n",
    "\n",
    "            # define variables specific to each config\n",
    "            if len(self.variables) > 0:\n",
    "                label = ': {}'.format(\n",
    "                    {param: model.params[param] for param in self.variables})\n",
    "                label = label.replace(\"{\", \"\")\n",
    "                label = label.replace(\"}\", \"\")\n",
    "                label = label.replace(\"'\", \"\")\n",
    "            else:\n",
    "                label = \"\"\n",
    "\n",
    "            # plot numerical output\n",
    "            sns.lineplot(data=model.attributes,\n",
    "                             y=\"tilt\", x=\"dist_km\", label=f'Numerical{label}')\n",
    "\n",
    "            if calc_mogi:\n",
    "                dist = np.array(model.attributes['dist'])\n",
    "                dist_km = dist / 1000\n",
    "                tilt = mogi_tilt(\n",
    "                    dist=dist,\n",
    "                    epv=model_epv,\n",
    "                    d=model.params['depth']\n",
    "                )\n",
    "                sns.lineplot(x=dist_km, y=tilt, label=f'Mogi (calc){label}')\n",
    "\n",
    "            if fit_mogi:\n",
    "                params, _ = fit_mogi_function(df=model.data)\n",
    "                epv, d = params\n",
    "\n",
    "                sns.lineplot(x=model.data['dist_km'], y=mogi_tilt(\n",
    "                    model.data['dist'], epv, d), label=f'Mogi (fit){label}')\n",
    "                \n",
    "                epv_overestimate = epv / model_epv\n",
    "                d_overestimate = d / model.params['depth']\n",
    "\n",
    "                title += '\\n Fitted parameter overestimation Factors: '\n",
    "                title += '$E_{PV}:$' + f'{round(epv_overestimate,2)}, '\n",
    "                title += '$d:$' + f'{round(d_overestimate, 2)}'\n",
    "\n",
    "\n",
    "        plt.title(f\"{title}\")\n",
    "        plt.xlabel(\"Distance (km)\")\n",
    "        # plt.xlim(8, 16) \n",
    "        # plt.ylim(.34, .37)\n",
    "        plt.ylabel(\"Tilt (deg)\")\n",
    "        plt.legend(loc=\"upper right\")\n",
    "\n",
    "        # save plot with name if passed as argument\n",
    "        if name is not None:\n",
    "            save_pdf(name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define specific parametric sweeps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grav_topo_test_sweep = ParamSweep({\n",
    "    \"depth\": [15_000],\n",
    "    \"radius\": [20_000],\n",
    "    \"aspect\": [.4],\n",
    "    \"pmult\": [.6],\n",
    "    \"grav\": [True, False],\n",
    "    \"topo\": [True, False],\n",
    "})\n",
    "\n",
    "mogi_shallow_oblate_test_sweep = ParamSweep({\n",
    "    \"depth\": [15_000],\n",
    "    \"radius\": [20_000],\n",
    "    \"aspect\": [.4],\n",
    "    \"pmult\": [.6],\n",
    "    \"grav\": [False],\n",
    "    \"topo\": [True],\n",
    "})\n",
    "\n",
    "mogi_test_sweep = ParamSweep({\n",
    "    \"depth\": [25_000],\n",
    "    \"radius\": [5_000],\n",
    "    \"aspect\": [1],\n",
    "    \"pmult\": [1],\n",
    "    \"grav\": [False],\n",
    "    \"topo\": [False],\n",
    "})\n",
    "\n",
    "full_sweep = ParamSweep({\n",
    "    \"depth\": [25_000],\n",
    "    \"radius\": [5_000],\n",
    "    \"aspect\": [1],\n",
    "    \"pmult\": [1],\n",
    "    \"grav\": [False],\n",
    "    \"topo\": [False],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grav_topo_test_sweep.plot()  # name='grav-topo-test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mogi_test_sweep.plot(calc_mogi=True, fit_mogi=True)  # name='mogi-test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name='mogi-test-shallow-oblate'\n",
    "mogi_shallow_oblate_test_sweep.plot(calc_mogi=True, fit_mogi=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for plotting a full center scatter plot against a numerical sweep. (Not used in manuscript)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_plot(sweep: ParamSweep, centers: list[Center], name: str = None): # type: ignore\n",
    "    fig = plt.figure(figsize=(8, 5), dpi=600)\n",
    "\n",
    "    for model in sweep.models:\n",
    "        label = '{}'.format({param: model.params[param] for param in sweep.variables})\n",
    "        label = label.replace(\"{\", \"\")\n",
    "        label = label.replace(\"}\", \"\")\n",
    "        label = label.replace(\"'\", \"\")\n",
    "        sns.lineplot(data=model.attributes, y=\"tilt\", x=\"dist_km\", label=label)\n",
    "\n",
    "    for center in centers:\n",
    "        sns.scatterplot(data=center.data, x='dist_km', y='tilt', label=center.cID)\n",
    "\n",
    "    model_title = f'{sweep.constants}'\n",
    "    model_title = model_title.replace(\"{\", \"\")\n",
    "    model_title = model_title.replace(\"}\", \"\")\n",
    "    model_title = model_title.replace(\"'\", \"\")\n",
    "    plt.title(f\"Radial Tilt: {model_title}\")\n",
    "\n",
    "    plt.title(f\"Model Parameters: {model_title}\")\n",
    "    plt.xlabel(\"Distance (km)\")\n",
    "    plt.ylabel(\"Tilt (deg)\")\n",
    "    plt.legend()\n",
    "\n",
    "    # save plot with name if passed as argument\n",
    "    if name is not None:\n",
    "        save_pdf(name)\n",
    "\n",
    "combined_plot(mogi_shallow_oblate_test_sweep, [centers_calc[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
